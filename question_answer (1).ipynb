{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"train.json\",\"r\") as read_file:\n",
    "          train = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'context': 'Mistborn is a series of epic fantasy novels written by American author Brandon Sanderson.',\n",
       "  'qas': [{'id': '00001',\n",
       "    'is_impossible': False,\n",
       "    'question': 'Who is the author of the Mistborn series?',\n",
       "    'answers': [{'text': 'Brandon Sanderson', 'answer_start': 71}]}]},\n",
       " {'context': 'The first series, published between 2006 and 2008, consists of The Final Empire,The Well of Ascension, and The Hero of Ages.',\n",
       "  'qas': [{'id': '00002',\n",
       "    'is_impossible': False,\n",
       "    'question': 'When was the series published?',\n",
       "    'answers': [{'text': 'between 2006 and 2008', 'answer_start': 28}]},\n",
       "   {'id': '00003',\n",
       "    'is_impossible': False,\n",
       "    'question': 'What are the three books in the series?',\n",
       "    'answers': [{'text': 'The Final Empire, The Well of Ascension, and The Hero of Ages',\n",
       "      'answer_start': 63}]},\n",
       "   {'id': '00004',\n",
       "    'is_impossible': True,\n",
       "    'question': 'Who is the main character in the series?',\n",
       "    'answers': []}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"test.json\",\"r\") as read_file:\n",
    "          test= json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'context': 'The series primarily takes place in a region called the Final Empire on a world called Scadrial, where the sun and sky are red, vegetation is brown, and the ground is constantly being covered under black volcanic ashfalls.',\n",
       "  'qas': [{'id': '00001',\n",
       "    'is_impossible': False,\n",
       "    'question': 'Where does the series take place?',\n",
       "    'answers': [{'text': 'region called the Final Empire', 'answer_start': 38},\n",
       "     {'text': 'world called Scadrial', 'answer_start': 74}]}]},\n",
       " {'context': '\"Mistings\" have only one of the many Allomantic powers, while \"Mistborns\" have all the powers.',\n",
       "  'qas': [{'id': '00002',\n",
       "    'is_impossible': False,\n",
       "    'question': 'How many powers does a Misting possess?',\n",
       "    'answers': [{'text': 'one', 'answer_start': 21}]},\n",
       "   {'id': '00003',\n",
       "    'is_impossible': True,\n",
       "    'question': 'What are Allomantic powers?',\n",
       "    'answers': []}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "from simpletransformers.question_answering import  QuestionAnsweringModel,QuestionAnsweringArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type=\"bert\"\n",
    "model_name=\"bert_base_cased\"\n",
    "if model_type==\"bert\":\n",
    "    model_name=\"bert-base-cased\"\n",
    "elif model_type==\"roberta\":\n",
    "    model_name=\"roberta-base\"\n",
    "elif model_type==\"distilbert\":\n",
    "    model_name=\"distilbert-base-cased\"\n",
    "elif model_type==\"distilroberta\":\n",
    "    model_type=\"roberta\"\n",
    "    model_name=\"distilroberta-base\"\n",
    "elif model_type==\"electra-base\":\n",
    "    model_type=\"electra\"\n",
    "    model_name=\"google/electra-base-discriminator\"\n",
    "elif model_type==\"electra-small\":\n",
    "    model_type=\"electra\"\n",
    "    model_name=\"xlnet-base-cased\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure the model\n",
    "model_args=QuestionAnsweringArgs()\n",
    "model_args.train_batch_size=16\n",
    "model_args.evaluate_during_training=True\n",
    "model_args.n_best_size=3\n",
    "model_args.num_train_epochs=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#advanced methodology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"use_cached_eval_features\": True,\n",
    "    \"output_dir\": f\"outputs/{model_type}\",\n",
    "    \"best_model_dir\": f\"outputs/{model_type}/best_model\",\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"max_seq_length\": 128,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"evaluate_during_training_steps\": 1000,\n",
    "    \"wandb_project\": \"Question Answer Application\",\n",
    "    \"wandb_kwargs\": {\"name\": model_name},\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"n_best_size\":3,\n",
    "    # \"use_early_stopping\": True,\n",
    "    # \"early_stopping_metric\": \"mcc\",\n",
    "    # \"n_gpu\": 2,\n",
    "    # \"manual_seed\": 4,\n",
    "    # \"use_multiprocessing\": False,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 64,\n",
    "    # \"config\": {\n",
    "    #     \"output_hidden_states\": True\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "model=QuestionAnsweringModel(\n",
    "    model_type,model_name,args=train_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 4/4 [00:00<00:00, 1322.39it/s]\n",
      "add example index and unique id: 100%|██████████| 4/4 [00:00<00:00, 7377.84it/s]\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:697: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:720: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/10. Running Loss:    4.8236: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:302: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(cached_features_file)\n",
      "c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:1184: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "Epochs 2/10. Running Loss:    4.7760: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "Epochs 3/10. Running Loss:    4.2865: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "Epochs 4/10. Running Loss:    3.8164: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "Epochs 5/10. Running Loss:    3.3408: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n",
      "Epochs 6/10. Running Loss:    2.8395: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "Epochs 7/10. Running Loss:    2.6748: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "Epochs 8/10. Running Loss:    2.3426: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "Epochs 9/10. Running Loss:    1.9242: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "Epochs 10/10. Running Loss:    1.9617: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [00:27<00:00,  2.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " {'global_step': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "  'correct': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "  'similar': [2, 3, 2, 2, 2, 2, 1, 1, 1, 1],\n",
       "  'incorrect': [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'train_loss': [4.823567867279053,\n",
       "   4.7760419845581055,\n",
       "   4.2864580154418945,\n",
       "   3.81640625,\n",
       "   3.3408203125,\n",
       "   2.8395180702209473,\n",
       "   2.6748046875,\n",
       "   2.3426105976104736,\n",
       "   1.9241535663604736,\n",
       "   1.961669921875],\n",
       "  'eval_loss': [-0.40869140625,\n",
       "   -0.49267578125,\n",
       "   -0.5771484375,\n",
       "   -0.6533203125,\n",
       "   -0.72119140625,\n",
       "   -0.78173828125,\n",
       "   -0.8330078125,\n",
       "   -0.873046875,\n",
       "   -0.90087890625,\n",
       "   -0.9150390625]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train th model\n",
    "model.train_model(train,eval_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "result,texts=model.eval_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 1, 'similar': 1, 'incorrect': 1, 'eval_loss': -0.9150390625}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction with the model \n",
    "to_predict=[\n",
    "    {\n",
    "        \"context\": \"Vin is a Mistborn of great power and skills.\",\n",
    "        \"qas\":[\n",
    "            {\n",
    "                \"question\": \"What is Vin's speciality?\",\n",
    "                \"id\":\"0\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 1678.39it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 1455.85it/s]\n",
      "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\karti\\Desktop\\qna\\qna\\Lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:1348: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0', 'answer': ['and skills']}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answers,probabilities=model.predict(to_predict)\n",
    "print(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
